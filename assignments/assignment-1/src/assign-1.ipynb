{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Analytics - Assignment 1 - Extracting linguistic features using spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../input/USEcorpus/USEcorpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating relative frequency of  Nouns, Verbs, Adjective and Adverbs PER 10,000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_frequencies(doc):\n",
    "    # create empty lists\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adjective_count = 0\n",
    "    adverb_count = 0\n",
    "    \n",
    "    # find frequencies \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun_count += 1\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            verb_count += 1\n",
    "        elif token.pos_ == \"ADJ\":\n",
    "            adjective_count += 1\n",
    "        elif token.pos_ == \"ADV\":\n",
    "            adverb_count += 1 \n",
    "        else:\n",
    "            pass \n",
    "\n",
    "    # find the relative frequency per 10,000 words  \n",
    "    relative_freq_noun = round(((noun_count/len(doc)) * 10000), 2)\n",
    "    relative_freq_verb = round(((verb_count/len(doc)) * 10000), 2) \n",
    "    relative_freq_adjective = round(((adjective_count/len(doc))* 10000), 2) \n",
    "    relative_freq_adverb = round(((adverb_count/len(doc)) * 10000), 2)\n",
    "\n",
    "    return(relative_freq_noun, relative_freq_verb, relative_freq_adjective, relative_freq_adverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the total number of unique PER, LOC and ORG entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique_entities(doc):\n",
    "     # create empty lists\n",
    "    PER_ent = []\n",
    "    LOC_ent = []\n",
    "    ORG_ent = []\n",
    "    \n",
    "    # find entities \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            PER_ent.append(ent.text)\n",
    "        elif ent.label_ == \"LOC\":\n",
    "            LOC_ent.append(ent.text)\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            ORG_ent.append(ent.text)\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "    # find the unique entities  \n",
    "    PER_ent_count = len(np.unique(PER_ent))\n",
    "    LOC_ent_count = len(np.unique(LOC_ent))\n",
    "    ORG_ent_count = len(np.unique(ORG_ent))\n",
    "    \n",
    "    return(PER_ent_count, LOC_ent_count, ORG_ent_count)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating 14 tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    subfolder = os.path.join(data_path, directory)\n",
    "    filenames = sorted(os.listdir(subfolder))\n",
    "    data = []\n",
    "    \n",
    "\n",
    "    # create file path \n",
    "    for text_file in filenames:\n",
    "        filepath = subfolder + \"/\" + text_file\n",
    "\n",
    "        # load file\n",
    "        with open(filepath, encoding = \"latin-1\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # remove metadata\n",
    "        text = re.sub(pattern = r'<.*?>', repl = \" \", string = text)\n",
    "\n",
    "        # create spaCy doc\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # extract relative frequency \n",
    "        relative_frequency = relative_frequencies(doc)\n",
    "        # extract unique entities \n",
    "        unique_entity = unique_entities(doc)\n",
    "\n",
    "        # create tuples using append\n",
    "        data.append((text_file, relative_frequency[0], relative_frequency[1], relative_frequency[2], relative_frequency[3], unique_entity[0], unique_entity[1], unique_entity[2]))\n",
    "\n",
    "    dataframe = pd.DataFrame(data, \n",
    "                    columns=[\"Filename\", \"RelFreq NOUN\", \"RelFreq VERB\", \"RelFreq ADJ\", \"RelFreq ADV\", \"No. Unique PER\", \"No. Unique LOC\", \"No. Unique ORG\"])\n",
    "    # save dataframe\n",
    "    outpath = os.path.join(\"..\", \"output\", f\"{directory}.csv\")\n",
    "    dataframe.to_csv(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
